
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Meta-Review of Artificial Intelligence in Higher Education: Trends, Gaps, and Future Directions</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
        }
        .toc {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .toc ul {
            list-style-type: none;
            padding-left: 20px;
        }
        .toc ul ul {
            padding-left: 20px;
        }
        .section {
            margin-bottom: 30px;
            border-bottom: 1px solid #eee;
            padding-bottom: 20px;
        }
        .quote {
            background-color: #e7f4ff;
            border-left: 5px solid #3498db;
            padding: 10px;
            margin: 10px 0;
            font-style: italic;
        }
        .back-to-top {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background-color: #3498db;
            color: white;
            padding: 10px 15px;
            border-radius: 5px;
            text-decoration: none;
            display: none;
        }
        details {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin-bottom: 10px;
        }
        summary {
            padding: 10px;
            cursor: pointer;
            font-weight: bold;
            background-color: #f0f0f0;
        }
        details > * {
            padding: 10px;
        }
        .critique-section {
            margin-bottom: 15px;
            padding: 10px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .critique-title {
            font-weight: bold;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        .aspect {
            margin-bottom: 10px;
            padding: 10px;
            background-color: #ffffff;
            border-radius: 4px;
        }
        .strength {
            border-left: 3px solid #2ecc71;
        }
        .suggestion {
            border-left: 3px solid #e74c3c;
        }
        .aspect-type {
            font-weight: bold;
            margin-bottom: 5px;
        }
        .non-text-description {
            padding-left: 20px;
            margin-left: 10px;
        }
        .non-text-element {
            margin-bottom: 15px;
            padding: 10px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .non-text-element ul {
            padding-left: 30px;
        }
        .first-mention {
            margin-top: 10px;
            padding: 10px;
            background-color: #f0f8ff;
            border-radius: 4px;
        }
        .first-mention h5 {
            margin-top: 0;
            color: #2c3e50;
        }
        @media (max-width: 600px) {
            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <h1>A Meta-Review of Artificial Intelligence in Higher Education: Trends, Gaps, and Future Directions</h1>
    
    <div class="toc">
        <h2>Table of Contents</h2>
        <ul>
            <li><a href="#overall-summary">Overall Summary</a></li>
            <li><a href="#section-analysis">Section Analysis</a>
                <ul>
                <li><a href="#section-0">Abstract</a></li><li><a href="#section-1">Introduction</a></li><li><a href="#section-2">Method</a></li><li><a href="#section-3">Findings</a></li><li><a href="#section-4">Discussion</a></li><li><a href="#section-5">Conclusion</a></li>
                </ul>
            </li>
        </ul>
    </div>
    
    <div id="overall-summary" class="section">
        <h2>Overall Summary</h2>
        <h3>Overview</h3>
        <p>This meta-review examines the growing field of Artificial Intelligence in Education (AIEd), specifically in higher education (AIHEd). Think of it like taking a bird&#39;s-eye view of all the existing summaries of AIEd research to understand the big picture. The review analyzes 66 summaries of AIEd research, published between 2018 and 2023, to identify key trends, research gaps, and areas for improvement. It&#39;s like creating a map of the AIEd landscape to guide future exploration.</p>
        
        <h3>Key Findings</h3>
        <ul>
        <li>Adaptive systems and personalization are the most common AI applications in higher education.</li><li>There&#39;s a concerning lack of attention to ethical considerations in many AIEd studies.</li><li>The quality of AIEd research is variable, with many studies lacking methodological rigor.</li><li>AIEd research is geographically concentrated, with limited representation from certain regions.</li><li>There&#39;s a need for more research on the practical implications of AIEd for educators and policymakers.</li>
        </ul>
        
        <h3>Strengths</h3>
        <ul>
        <li>The review uses a comprehensive search strategy, covering multiple databases and platforms.</li><li>The review employs clear inclusion and exclusion criteria, ensuring a focused analysis.</li><li>The review provides transparent reporting of its methods, allowing for replication and scrutiny.</li>
        </ul>
        
        <h3>Areas for Improvement</h3>
        <ul>
        <li>A deeper analysis of the specific methodological weaknesses in AIEd studies and their impact on the findings would be valuable.</li><li>Further exploration of the reasons behind regional variations in AIEd research would provide a more nuanced understanding of the global landscape.</li>
        </ul>
        
        <h3>Significant Elements</h3>
        
    <div>
        <h4>Table 8</h4>
        <p><strong>Description:</strong> This table lists the top research gaps identified in AIEd, such as ethical implications, methodological limitations, and the need for more diverse research contexts.</p>
        <p><strong>Relevance:</strong> It provides a roadmap for future research, highlighting the most pressing issues that need to be addressed.</p>
    </div>
    
    <div>
        <h4>Figure 5</h4>
        <p><strong>Description:</strong> This figure shows the trend of AIEd publications over time, indicating a growing interest in the field.</p>
        <p><strong>Relevance:</strong> It provides context for the meta-review, showing how AIEd research has evolved over the past few years.</p>
    </div>
    
        
        <h3>Conclusion</h3>
        <p>This meta-review reveals a rapidly growing yet unevenly developed field of AIEd in higher education. While AI offers great potential for personalized learning and improved educational outcomes, think of it like a powerful new tool that can be used for good or bad. Addressing the identified challenges, particularly ethical concerns and methodological limitations, is crucial for realizing AI&#39;s full potential and ensuring its responsible use in higher education. It&#39;s like building a bridge to the future of education – we need strong foundations and careful planning to make sure it&#39;s safe and effective.</p>
    </div>
    
    <div id="section-analysis" class="section">
        <h2>Section Analysis</h2>
        
        <div id="section-0" class="section">
            <h3>Abstract</h3>
            
            <h4>Overview</h4>
            <p>This abstract summarizes a meta-review of research on Artificial Intelligence in Education (AIEd), specifically in higher education (AIHEd). It highlights the rapid growth of AIEd and the importance of a strong research base. The review synthesized secondary research, primarily systematic reviews, to explore the scope and nature of AIEd research, identifying key themes, research gaps, and suggestions for future research.</p>
            
            <h4>Key Aspects</h4>
            <ul><li><strong>Scope of AIEd in Higher Education:</strong> The review synthesized secondary research to explore the extent and nature of AIEd research in higher education.</li><li><strong>Methodology of the Review:</strong> The review included systematic reviews, indexed in various databases, and used a systematic process for data extraction and synthesis.</li><li><strong>Key Themes in AIHEd Research:</strong> The review identified a focus on general AIHEd and Profiling and Prediction, with a predominance of Adaptive Systems and Personalisation.</li><li><strong>Research Gaps:</strong> The review highlighted the need for more research on ethical considerations, methodology, and context within AIHEd.</li><li><strong>Future Research Directions:</strong> The review provides suggestions to guide future primary and secondary research in AIHEd.</li></ul>
            
            <h4>Strengths</h4>
            <ul>
            
    <li>
        <strong>Clear Scope and Purpose</strong>
        <p>The abstract clearly defines the scope of the review, focusing on AIEd in higher education, and its purpose, which is to synthesize existing research and identify gaps.</p>
        <div class="quote">"This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research" (Page 1)</div>
    </li>
    
    <li>
        <strong>Concise Summary of Methodology</strong>
        <p>The abstract provides a concise summary of the review methodology, including the types of research synthesized and the databases used.</p>
        <div class="quote">"by synthesising secondary research (e.g., systematic reviews), indexed in the Web of Science, Scopus, ERIC, EBSCOHost, IEEE Xplore, ScienceDirect and ACM Digital Library" (Page 1)</div>
    </li>
    
    <li>
        <strong>Highlights Key Findings and Gaps</strong>
        <p>The abstract effectively highlights the key findings of the review, such as the focus on Adaptive Systems and Personalisation, and identifies important research gaps, like the need for greater ethical considerations.</p>
        <div class="quote">"Findings show that these reviews mostly focused on AIHEd generally (47.0%) or Profiling and Prediction (28.8%) as thematic foci, however key findings indicated a predominance of the use of Adaptive Systems and Personalisation in higher education. Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research" (Page 1)</div>
    </li>
    
            </ul>
            
            <h4>Suggestions for Improvement</h4>
            <ul>
            
    <li>
        <strong>Expand on the types of AI applications</strong>
        <p>While the abstract mentions Adaptive Systems and Personalisation, briefly mentioning other key AI applications would provide a more complete picture of the review&#39;s scope.</p>
        <div class="quote">"Findings show that these reviews mostly focused on AIHEd generally (47.0%) or Profiling and Prediction (28.8%) as thematic foci" (Page 1)</div>
        <p><strong>Rationale:</strong> This would give readers a better understanding of the specific AI technologies being investigated in higher education.</p>
        <p><strong>Implementation:</strong> Include a brief mention of other prominent AI applications, such as Intelligent Tutoring Systems or Assessment and Evaluation, if they are also addressed in the review.</p>
    </li>
    
    <li>
        <strong>Elaborate on the implications of the research gaps</strong>
        <p>The abstract identifies research gaps but could briefly explain why addressing these gaps is important for the future of AIEd.</p>
        <div class="quote">"Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research" (Page 1)</div>
        <p><strong>Rationale:</strong> This would highlight the significance of the review&#39;s findings and motivate further research in the identified areas.</p>
        <p><strong>Implementation:</strong> Add a sentence briefly explaining the potential consequences of not addressing these gaps, such as the risk of biased or ineffective AI applications in education.</p>
    </li>
    
    <li>
        <strong>Quantify the scope of the review</strong>
        <p>The abstract mentions synthesizing secondary research but could strengthen its impact by quantifying the number of reviews included.</p>
        <div class="quote">"synthesising secondary research (e.g., systematic reviews)" (Page 1)</div>
        <p><strong>Rationale:</strong> This would provide a clearer indication of the comprehensiveness of the review and the breadth of the literature synthesized.</p>
        <p><strong>Implementation:</strong> Include the number of secondary research articles included in the review, e.g., &quot;This review synthesized findings from X secondary research articles...&quot;</p>
    </li>
    
            </ul>
            
            
        </div>
        
        <div id="section-1" class="section">
            <h3>Introduction</h3>
            
            <h4>Overview</h4>
            <p>This introduction sets the stage for a meta-review of research on Artificial Intelligence in Education (AIEd), specifically in higher education. It emphasizes the growing importance of AIEd, the need for a solid research foundation, and the timeliness of this review due to the rapid evolution of AI and increased public discourse.</p>
            
            <h4>Key Aspects</h4>
            <ul><li><strong>Historical Context of AIEd:</strong> AIEd has been a research domain for decades, but the recent rise of AI applications has brought it into public discussion.</li><li><strong>Rationale for the Review:</strong> The rapid growth of AIEd literature necessitates a comprehensive review to ensure a solid research grounding.</li><li><strong>Focus on Higher Education:</strong> This review specifically targets AIEd in higher education (AIHEd) to address the unique challenges and opportunities in this context.</li><li><strong>Tertiary Review Approach:</strong> This is the first comprehensive meta-review of AIHEd, synthesizing existing reviews for a broader perspective.</li><li><strong>Timeliness of the Review:</strong> The rise of generative AI, like ChatGPT, makes this review timely and crucial for guiding future AIEd development.</li></ul>
            
            <h4>Strengths</h4>
            <ul>
            
    <li>
        <strong>Clear Justification for the Review</strong>
        <p>The introduction effectively justifies the need for this review by highlighting the rapid growth of AIEd literature and the lack of a comprehensive overview.</p>
        <div class="quote">"Given the already rapidly growing AIEd literature base in higher education, now is the time to ensure that the field has a solid research and conceptual grounding." (Page 1)</div>
    </li>
    
    <li>
        <strong>Establishes the Review&#39;s Significance</strong>
        <p>The introduction clearly establishes the significance of the review by emphasizing its comprehensive nature and its role in providing a foundation for future research.</p>
        <div class="quote">"This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research" (Page 1)</div>
    </li>
    
    <li>
        <strong>Contextualizes AIEd within Broader Trends</strong>
        <p>The introduction effectively contextualizes AIEd within the broader trends of AI evolution and public discourse, highlighting the relevance and timeliness of the review.</p>
        <div class="quote">"never before has the rapid evolution of AI applications in education sparked such prominent public discourse." (Page 1)</div>
    </li>
    
            </ul>
            
            <h4>Suggestions for Improvement</h4>
            <ul>
            
    <li>
        <strong>Provide Specific Examples of AI Applications</strong>
        <p>While the introduction mentions AI applications generally, providing specific examples of AI tools used in higher education would make the context more concrete.</p>
        <div class="quote">"never before has the rapid evolution of AI applications in education sparked such prominent public discourse." (Page 1)</div>
        <p><strong>Rationale:</strong> This would help readers unfamiliar with AIEd grasp the practical implications of the review.</p>
        <p><strong>Implementation:</strong> Include examples like personalized learning platforms, automated grading systems, or AI-powered chatbots for student support.</p>
    </li>
    
    <li>
        <strong>Briefly Mention the Review&#39;s Methodology</strong>
        <p>While the abstract covers the methodology, briefly mentioning the type of review (meta-review) and the data sources in the introduction would enhance clarity.</p>
        <div class="quote">"This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research" (Page 1)</div>
        <p><strong>Rationale:</strong> This would reinforce the review&#39;s approach and provide context for the findings.</p>
        <p><strong>Implementation:</strong> Add a sentence like, &quot;This meta-review synthesizes findings from existing reviews indexed in various databases...&quot;</p>
    </li>
    
    <li>
        <strong>Preview Key Challenges and Opportunities</strong>
        <p>While the introduction mentions challenges generally, briefly previewing specific challenges and opportunities in AIHEd would create more interest.</p>
        <div class="quote">"now is the time to ensure that the field has a solid research and conceptual grounding." (Page 1)</div>
        <p><strong>Rationale:</strong> This would give readers a glimpse into the complexities of AIEd and the potential impact of the review.</p>
        <p><strong>Implementation:</strong> Include a sentence like, &quot;This review explores key challenges such as ethical considerations and bias in AIEd, as well as opportunities for personalized learning and improved student support.&quot;</p>
    </li>
    
            </ul>
            
            
        </div>
        
        <div id="section-2" class="section">
            <h3>Method</h3>
            
            <h4>Overview</h4>
            <p>This section details the methods used to conduct a tertiary review (a review of reviews) of AI in higher education. It describes the search strategy, study selection process, data extraction methods, quality assessment criteria, and data synthesis approach. The goal is to provide a transparent and replicable methodology for mapping the AIEd field.</p>
            
            <h4>Key Aspects</h4>
            <ul><li><strong>Search Strategy:</strong> A comprehensive search was conducted across multiple databases and platforms, including Web of Science, Scopus, ERIC, and OpenAlex, using an iterative approach and a predefined search string.</li><li><strong>Study Selection:</strong> Studies were included if they were secondary research on AI in higher education, published in English between 2018 and July 2023, and had a method section. Reviews focusing on generative AI like ChatGPT were excluded.</li><li><strong>Data Extraction:</strong> Data extracted included publication details, review type, focus, educational context, methodological characteristics, key findings, and research gaps.</li><li><strong>Quality Assessment:</strong> A modified DARE tool, incorporating elements from AMSTAR 2 and bespoke criteria, was used to assess the quality of the included reviews.</li><li><strong>Data Synthesis:</strong> A narrative synthesis was conducted, and interactive evidence and gap maps were created using EPPI Mapper for visualization and public access.</li></ul>
            
            <h4>Strengths</h4>
            <ul>
            
    <li>
        <strong>Comprehensive Search Strategy</strong>
        <p>The search strategy is comprehensive, covering multiple relevant databases and platforms, which increases the likelihood of capturing a wide range of studies.</p>
        <div class="quote">"The platforms and databases searched were the Web of Science, Scopus, ERIC, EBSCOHost (all databases), IEEE Xplore, Science Direct and ACM Digital Library" (Page 7)</div>
    </li>
    
    <li>
        <strong>Clear Inclusion/Exclusion Criteria</strong>
        <p>The inclusion and exclusion criteria are well-defined, ensuring that the review focuses specifically on relevant secondary research on AI in higher education.</p>
        <div class="quote">"Studies were included if they were a form of secondary research on AI applications within formal education settings, with an explicit method section and had been published after January 2018." (Page 9)</div>
    </li>
    
    <li>
        <strong>Transparent Reporting</strong>
        <p>The method section is transparent, providing details about the search strategy, study selection, data extraction, and quality assessment, allowing for replication and scrutiny.</p>
        <div class="quote">"All search information can be found on the OSF." (Page 7)</div>
    </li>
    
            </ul>
            
            <h4>Suggestions for Improvement</h4>
            <ul>
            
    <li>
        <strong>Manual Search of Key Journals</strong>
        <p>While the database search is extensive, manually searching key journals specific to AI in education could identify additional relevant studies not indexed in databases.</p>
        <div class="quote">"The platforms and databases searched were the Web of Science, Scopus, ERIC, EBSCOHost (all databases), IEEE Xplore, Science Direct and ACM Digital Library" (Page 7)</div>
        <p><strong>Rationale:</strong> This would ensure that important studies published in niche journals are not missed.</p>
        <p><strong>Implementation:</strong> Manually search the tables of contents of key journals like &quot;Computers &amp; Education: Artificial Intelligence&quot; or other relevant publications.</p>
    </li>
    
    <li>
        <strong>Clarify Rationale for Excluding Generative AI Reviews</strong>
        <p>While the exclusion of generative AI reviews is mentioned, providing a clearer rationale for this decision would strengthen the methodology.</p>
        <div class="quote">"Although reviews have already started being published on the topic of generative AI, and ChatGPT in particular (e.g., İpek et al., 2023; Lo, 2023), the decision was made to exclude these from this sample" (Page 9)</div>
        <p><strong>Rationale:</strong> This would address potential concerns about the scope of the review and justify the focus on pre-generative AI research.</p>
        <p><strong>Implementation:</strong> Explain why generative AI represents a distinct phase of AIEd, requiring a separate review, and how this exclusion contributes to the current review&#39;s focus.</p>
    </li>
    
    <li>
        <strong>Provide More Detail on Inductive Coding</strong>
        <p>The method section mentions inductive coding for key findings and research gaps but could provide more detail on the process.</p>
        <div class="quote">"All data were extracted manually and input into EPPI Reviewer (Thomas et al., 2023), including author affiliations and countries" (Page 10)</div>
        <p><strong>Rationale:</strong> This would enhance transparency and allow readers to understand how these themes were derived from the data.</p>
        <p><strong>Implementation:</strong> Describe the steps involved in the inductive coding process, such as initial open coding, axial coding to identify relationships between codes, and selective coding to develop overarching themes.</p>
    </li>
    
            </ul>
            
            
    <h4>Non-Text Elements</h4>
    
    <details class="non-text-element">
        <summary>figure 2</summary>
        <p>Figure 2 presents the search string used for the tertiary review. It&#39;s organized into three main search components combined with &quot;AND&quot;: AI, Education Sector, and Evidence Synthesis. Each component lists specific keywords or phrases used in the search, separated by &quot;OR&quot;. For example, the AI component includes terms like &quot;artificial intelligence,&quot; &quot;machine learning,&quot; &quot;chat bot*&quot;, and various other related terms. The Education Sector component specifies educational levels and settings like &quot;higher education,&quot; &quot;college*&quot;, &quot;K-12&quot;, and other related terms. The Evidence Synthesis component lists different types of review methodologies, such as &quot;systematic review,&quot; &quot;scoping review,&quot; &quot;meta-analysis,&quot; and many others.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "A search string was developed (see Fig. 2) based on the search strings from the two previous reviews"</p>
            <p><strong>Context:</strong> The authors explain how they developed their search string for the review, mentioning that it was based on previous reviews and focuses on AI, education settings, and evidence synthesis methods.</p>
        </div>
        
        <p><strong>Relevance:</strong> This figure is crucial as it provides transparency and replicability for the review process. It shows exactly how the authors searched for relevant literature, allowing others to understand and potentially reproduce the search.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The figure clearly presents the search string in a structured and readable format.</li><li>The use of &#39;AND&#39; and &#39;OR&#39; operators is clearly shown, making the search logic easy to follow.</li><li>The grouping of search terms into categories (AI, Education Sector, Evidence Synthesis) enhances clarity.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The search string appears comprehensive, covering a wide range of relevant terms for AI, education levels, and review types.</li><li>The use of wildcards (e.g., &#39;bot*&#39;) is helpful for capturing variations of search terms.</li><li>The search string could be improved by adding specific terms related to higher education contexts, such as &#39;university&#39; or &#39;tertiary education&#39;, to further refine the search.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        </ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>figure 3</summary>
        <p>Figure 3, a PRISMA flow diagram, visually represents the process of selecting studies for inclusion in the meta-review. It starts with the initial number of records identified through database searching and other sources. Then, it shows the number of records after duplicates were removed. The diagram then details the screening process, showing how many records were screened based on title and abstract, and how many were excluded at this stage with reasons for exclusion. It proceeds to full-text screening, again showing exclusions and reasons. Finally, it shows the number of studies included in the review.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "The search strategy yielded 5609 items (see Fig. 3), which were exported as .ris or .txt files and imported into the evidence synthesis software EPPI Reviewer"</p>
            <p><strong>Context:</strong> This quote describes the initial stage of the study selection process, where the search results are imported into EPPI Reviewer software for further processing.</p>
        </div>
        
        <p><strong>Relevance:</strong> This figure is essential for understanding the scope and rigor of the review. It clearly shows how many studies were considered and why some were excluded, ensuring transparency and allowing readers to assess the review&#39;s comprehensiveness.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The diagram is clear and easy to follow, using standard PRISMA formatting.</li><li>The numbers of included and excluded studies at each stage are clearly displayed.</li><li>The reasons for exclusion are provided, which is helpful for understanding the selection process.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The diagram effectively communicates the iterative nature of the review process.</li><li>The large number of excluded studies highlights the importance of a systematic approach to literature selection.</li><li>The diagram could be further improved by providing more detail on the specific criteria used for each screening stage.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        </ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 2</summary>
        <p>Table 2 outlines the criteria used to include or exclude studies from the meta-review. It&#39;s divided into two columns: &#39;Inclusion criteria&#39; and &#39;Exclusion criteria&#39;. The &#39;Inclusion criteria&#39; column lists factors like the publication date range (January 2018 to July 18, 2023), the focus on AI applications in formal education settings, the type of publication (journal articles or conference papers), the use of secondary research with a method section, and the language (English). The &#39;Exclusion criteria&#39; column lists factors like publications before January 2018, studies not about AI or not in formal education settings, specific publication types (editorials, book chapters, etc.), primary research or literature reviews without a method section, and non-English publications.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "following lengthy discussion and agreement on the inclusion and exclusion criteria by all authors, two members of the team (MB and PP) double screened the first 100 items"</p>
            <p><strong>Context:</strong> This section describes the process of ensuring inter-rater reliability during the screening process, emphasizing the importance of agreed-upon inclusion and exclusion criteria.</p>
        </div>
        
        <p><strong>Relevance:</strong> This table is crucial for understanding the scope and focus of the review. It clearly defines which studies were eligible for inclusion and why, ensuring transparency and allowing readers to assess the review&#39;s relevance to their own interests.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is clearly organized with distinct columns for inclusion and exclusion criteria.</li><li>The criteria are presented in a concise and easy-to-understand manner.</li><li>The table could be improved by adding a brief explanation of the rationale behind each criterion.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The criteria appear well-defined and relevant to the review&#39;s focus on AI in higher education.</li><li>The exclusion of certain publication types (e.g., editorials, book chapters) helps to focus the review on research-based evidence.</li><li>The inclusion criteria could be strengthened by specifying the types of AI applications or educational contexts of interest.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        </ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>figure 4</summary>
        <p>Figure 4 provides a table outlining the criteria used for assessing the quality of the included reviews. Each criterion is listed along with a scoring system (Yes = 1, Partly = 0.5, No = 0) and an interpretation of what each score represents. The criteria include aspects like the presence of research questions, the clarity of inclusion/exclusion criteria, the definition of publication years, the adequacy of the search strategy, the reporting of inter-rater reliability, and the provision of a data extraction coding scheme. It also assesses whether a quality assessment was conducted, if sufficient details about the included studies were provided, and if the review reflects on its limitations.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "To answer sub-question 1f about the quality of AIHEd secondary research, the decision was made to use the DARE tool (Centre for Reviews and Dissemination, 1995), which has been used in previous tertiary reviews (e.g., Kitchenham et al., 2009; Tran et al., 2021)."</p>
            <p><strong>Context:</strong> This section of the paper discusses the quality assessment methods employed in the meta-review. It explains the rationale for choosing the DARE tool and lists the criteria used for evaluating the quality of the included reviews. The criteria are presented in a table format in Figure 4.</p>
        </div>
        
        <p><strong>Relevance:</strong> This figure is crucial as it makes the review process transparent and allows readers to understand how the quality of the included studies was judged. By outlining the specific criteria and their scoring, it provides a clear framework for evaluating the rigor and reliability of the synthesized evidence. This helps establish the trustworthiness of the meta-review&#39;s findings.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table format is clear and easy to understand.</li><li>The use of simple language for the criteria and interpretations makes it accessible to a wider audience.</li><li>The scoring system is straightforward and easy to apply.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The criteria cover important aspects of review quality, such as the clarity of research questions, the adequacy of the search strategy, and the reporting of inter-rater reliability.</li><li>The inclusion of criteria related to transparency, like the provision of a data extraction coding scheme, strengthens the rigor of the quality assessment.</li><li>The criteria align with established quality assessment tools like DARE and AMSTAR 2, enhancing the credibility of the evaluation.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        </ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>figure 6</summary>
        <p>Figure 6 is a bar chart showing the overall quality assessment of the 66 AIHEd reviews included in the meta-review. The chart categorizes the reviews into five quality levels: Critically Low, Low, Medium, High, and Excellent. The height of each bar represents the number of reviews that fall into each quality category.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "The reviews were given an overall quality assessment score out of 10 (see Fig. 6), averaging 6.57 across the corpus."</p>
            <p><strong>Context:</strong> This part of the paper discusses the overall quality of the AIHEd reviews included in the meta-review. It mentions that each review received a score out of 10 and that the average score was 6.57. Figure 6 visually represents the distribution of these quality scores.</p>
        </div>
        
        <p><strong>Relevance:</strong> This figure is important because it provides a visual summary of the overall quality of the reviews included in the meta-review. It helps readers quickly grasp the distribution of quality levels and understand the general rigor of the synthesized evidence. This is essential for interpreting the findings and conclusions of the meta-review.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The bar chart format is effective for showing the distribution of quality levels.</li><li>Clear labels on the x and y axes make the chart easy to interpret.</li><li>The use of distinct colors for each bar enhances visual clarity.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The categorization of reviews into five quality levels provides a nuanced view of the quality assessment.</li><li>The chart highlights the proportion of reviews that fall into each quality category, allowing for a quick assessment of the overall quality of the included studies.</li><li>The visual representation of the quality assessment complements the detailed criteria provided in Figure 4, offering a more comprehensive understanding of the review process.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>Critically Low:</strong> 2 reviews</li><li><strong>Low:</strong> 8 reviews</li><li><strong>Medium:</strong> 33 reviews</li><li><strong>High:</strong> 17 reviews</li><li><strong>Excellent:</strong> 6 reviews</li></ul></div>
    </details>
    
    
        </div>
        
        <div id="section-3" class="section">
            <h3>Findings</h3>
            
            <h4>Overview</h4>
            <p>This section presents the findings of the meta-review on AI in higher education. It covers the publication trends, types of reviews conducted, author demographics, quality assessment of the reviews, common AI applications, benefits and challenges, and identified research gaps.</p>
            
            <h4>Key Aspects</h4>
            <ul><li><strong>Publication Trends:</strong> An increasing trend of AIEd publications, with a slight dip in 2020 likely due to the pandemic.</li><li><strong>Types of Reviews:</strong> Systematic reviews are the most common type of evidence synthesis in AIHEd.</li><li><strong>Author Demographics:</strong> AIHEd research is globally distributed, with North America, Europe, and Asia leading in contributions. Most research is domestically co-authored.</li><li><strong>Quality Assessment:</strong> The quality of AIHEd reviews is variable, with a concerning number lacking rigor in database searching, quality assessment, and reporting of methods.</li><li><strong>AI Applications:</strong> Adaptive systems and personalization, along with profiling and prediction, are the most common AI applications in higher education.</li><li><strong>Benefits and Challenges:</strong> Key benefits include personalized learning and reduced teacher workload. Ethical considerations and lack of technical knowledge are major challenges.</li><li><strong>Research Gaps:</strong> Ethical implications, methodological rigor, broader stakeholder involvement, and research in diverse contexts are identified as key research gaps.</li></ul>
            
            <h4>Strengths</h4>
            <ul>
            
    <li>
        <strong>Comprehensive Overview of Findings</strong>
        <p>The section provides a comprehensive overview of the findings, covering various aspects of AIEd research, from publication trends to research gaps.</p>
        <div class="quote">"Of the 66 evidence syntheses identified solely focused on AIEd in higher education (AIHEd), the majority were published as journal articles (81.8%, n = 54), as opposed to conference papers (n = 12), but only 67.6% are available open access." (Page 13)</div>
    </li>
    
    <li>
        <strong>Data-Driven Analysis</strong>
        <p>The findings are presented with supporting data and statistics, which strengthens the analysis and provides a clear picture of the AIEd research landscape.</p>
        <div class="quote">"Systematic literature reviews were by far the most popular type, accounting for two thirds of the corpus (66.7%, n = 44), followed by scoping reviews (12.1%, n = 8)." (Page 14)</div>
    </li>
    
    <li>
        <strong>Clear Presentation of Key Themes</strong>
        <p>The section clearly presents the key themes emerging from the meta-review, such as the prevalence of adaptive systems and personalization, making the findings accessible and easy to understand.</p>
        <div class="quote">"More than half of the reviews (54.5%, n = 36) discussed applications related to adaptive systems and personalisation, closely followed by profiling and prediction (48.5%, n = 32)" (Page 18)</div>
    </li>
    
            </ul>
            
            <h4>Suggestions for Improvement</h4>
            <ul>
            
    <li>
        <strong>Deeper Analysis of Quality Issues</strong>
        <p>While the section mentions quality concerns, a deeper analysis of the specific methodological weaknesses and their potential impact on the findings would be beneficial.</p>
        <div class="quote">"The most concerning findings were that 31.8% of studies only searched in one or two databases, 51.5% did not report anything about inter-rater reliability or how screening and coding decisions were decided between review teams, only 24.2% provided their exact data extraction coding scheme, 45.5% did not undertake any form of quality assessment, and 34.8% did not reflect at all upon the limitations of their review." (Page 16)</div>
        <p><strong>Rationale:</strong> This would provide a more critical perspective on the state of AIEd research and highlight areas for improvement.</p>
        <p><strong>Implementation:</strong> Discuss the potential biases or limitations introduced by these methodological weaknesses and how they might affect the generalizability or reliability of the findings.</p>
    </li>
    
    <li>
        <strong>Further Exploration of Regional Differences</strong>
        <p>The section notes regional variations in research but could further explore the reasons behind these differences and their implications.</p>
        <div class="quote">"Authorship was spread across 32 different countries (see Additional file 9: Appendix I), with arguably less dominance by the United States than two other recent EdTech tertiary reviews (Buntins et al., 2023; Zawacki-Richter, 2023) have found." (Page 15)</div>
        <p><strong>Rationale:</strong> This would provide a more nuanced understanding of the global AIEd landscape and inform strategies for promoting international collaboration.</p>
        <p><strong>Implementation:</strong> Investigate factors like funding priorities, research infrastructure, or cultural contexts that might contribute to regional variations in AIEd research.</p>
    </li>
    
    <li>
        <strong>Connect Findings to Implications for Practice</strong>
        <p>While the section presents the findings, connecting them more explicitly to their implications for educators and policymakers would enhance the practical relevance of the review.</p>
        <div class="quote">"This review of reviews confirms that the benefits of AI in higher education are multifold." (Page 32)</div>
        <p><strong>Rationale:</strong> This would bridge the gap between research and practice and provide actionable insights for stakeholders.</p>
        <p><strong>Implementation:</strong> Discuss how the findings can inform the design, implementation, and evaluation of AIEd initiatives in higher education institutions. Provide specific examples of how the findings can be translated into practical strategies or recommendations.</p>
    </li>
    
            </ul>
            
            
    <h4>Non-Text Elements</h4>
    
    <details class="non-text-element">
        <summary>figure 5</summary>
        <p>Figure 5 is a bar chart illustrating the number of AIEd evidence syntheses focused on higher education published each year from 2018 to 2023. Each bar represents a year, and its height corresponds to the number of publications. It shows a low number of publications in the initial years (2 in 2018, 10 in 2019), a dip in 2020 (6), a significant rise in 2021 and 2022 (16 and 20 respectively), and a slight decrease in 2023 (12).</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "there was a slight reduction in the number published in 2020 before rising again (see Fig. 5)."</p>
            <p><strong>Context:</strong> The authors are discussing the general publication characteristics of the AIEd evidence syntheses included in their review. They note a decrease in publications in 2020, likely due to the COVID-19 pandemic, before the numbers rise again. Figure 5 visually represents this trend.</p>
        </div>
        
        <p><strong>Relevance:</strong> This figure helps visualize the growth and trends in AIEd research publications specifically focused on higher education. It provides context for the review by showing the increasing interest in this area over recent years, while also acknowledging the impact of external factors like the pandemic.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The bar chart is clear and easy to understand, effectively showing the trend of publications over time.</li><li>The labels for the years and the number of publications are clear and easy to read.</li><li>The use of color enhances the visual appeal and readability of the chart.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The figure clearly demonstrates the increasing interest in AIEd research in higher education.</li><li>The dip in publications in 2020 provides an interesting data point for further investigation and discussion.</li><li>The figure could be improved by adding a trend line or a cumulative count of publications to further emphasize the growth in this area.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>2018:</strong> 2 publications</li><li><strong>2019:</strong> 10 publications</li><li><strong>2020:</strong> 6 publications</li><li><strong>2021:</strong> 16 publications</li><li><strong>2022:</strong> 20 publications</li><li><strong>2023:</strong> 12 publications</li></ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 3</summary>
        <p>Table 3 shows the top nine most productive countries in terms of authorship in AIEd evidence syntheses focused on higher education. It lists the countries, their rank, the number of publications from each country, and the percentage of the total publications each country represents. The United States is the most productive, followed by Canada and Australia.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "Whilst it was the most productive country (see Table 3), the United States was closely followed by Canada and Australia."</p>
            <p><strong>Context:</strong> The authors are discussing the geographical distribution of AIEd evidence synthesis authorship. They mention that the US is the most productive country, but Canada and Australia are close behind. Table 3 provides the data supporting this statement.</p>
        </div>
        
        <p><strong>Relevance:</strong> This table provides insights into the global distribution of research on AI in higher education. It shows which countries are leading in this area and can be used to identify potential collaborations or areas for future research development.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is clear and easy to read, with a simple and effective layout.</li><li>The inclusion of both count and percentage data provides a comprehensive view of each country&#39;s contribution.</li><li>The ranking helps to quickly identify the most productive countries.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The table shows a relatively diverse range of countries contributing to AIEd research, which is a positive sign for the field.</li><li>The dominance of North America and Australia could be further explored to understand the factors contributing to their higher publication rates.</li><li>The table could be enhanced by adding information about the types of AI applications or research methods used in each country.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>United States:</strong> 11 publications</li><li><strong>Canada:</strong> 9 publications</li><li><strong>Australia:</strong> 7 publications</li><li><strong>South Africa:</strong> 6 publications</li><li><strong>China:</strong> 5 publications</li><li><strong>Saudi Arabia:</strong> 4 publications</li><li><strong>Spain:</strong> 4 publications</li><li><strong>Germany:</strong> 3 publications</li><li><strong>India:</strong> 3 publications</li></ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 4</summary>
        <p>Table 4 presents a quality assessment of the 66 AIEd evidence syntheses included in the review. It lists ten criteria used to evaluate the quality of each review, along with the percentage of reviews that fully met (Yes), partially met (Partly), did not meet (No), or for which the criteria were not applicable (N/A). The criteria include having research questions, inclusion/exclusion criteria, defined publication years, an adequate search, a provided search string, reported inter-rater reliability, a data extraction coding scheme, a quality assessment, sufficient details about included studies, and a reflection on limitations.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "The AIHEd reviews in the corpus were assessed against 10 quality assessment criteria (see Table 4), based on the DARE (Centre for Reviews and Dissemination, 1995; Kitchenham et al., 2009) and AMSTAR 2 (Shea et al., 2017) tools, as well as the method by Buntins et al. (2023)."</p>
            <p><strong>Context:</strong> The authors are explaining how they assessed the quality of the AIHEd reviews included in their meta-review. They mention using a combination of criteria from the DARE and AMSTAR 2 tools, as well as a method by Buntins et al. (2023). Table 4 details these criteria and the results of the quality assessment.</p>
        </div>
        
        <p><strong>Relevance:</strong> This table is crucial for understanding the rigor and reliability of the included reviews. It provides a transparent overview of the quality assessment process and allows readers to assess the trustworthiness of the meta-review&#39;s findings.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is well-organized and easy to read, with clear headings and labels.</li><li>The use of percentages allows for easy comparison across criteria.</li><li>The inclusion of &#39;N/A&#39; acknowledges that some criteria may not be applicable to all review types.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The criteria cover important aspects of review quality, such as the clarity of research questions, the adequacy of the search strategy, and the reporting of inter-rater reliability.</li><li>The table highlights areas where AIEd reviews could be improved, such as the reporting of inter-rater reliability and the provision of data extraction coding schemes.</li><li>The quality assessment provides valuable insights into the methodological rigor of the AIEd research landscape.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>Research questions, aims or objectives:</strong> 92.4 %</li><li><strong>Inclusion/exclusion criteria reported and appropriate:</strong> 77.3 %</li><li><strong>Publication years included defined:</strong> 87.9 %</li><li><strong>Search adequately conducted and likely to have covered all relevant studies:</strong> 68.2 %</li><li><strong>Search string provided in full:</strong> 68.2 %</li><li><strong>Inter-rater reliability reported:</strong> 51.5 %</li><li><strong>Data extraction coding scheme provided:</strong> 24.2 %</li><li><strong>Quality assessment undertaken:</strong> 45.5 %</li><li><strong>Sufficient details provided about the individual included studies:</strong> 65.2 %</li><li><strong>Reflection on review limitations:</strong> 65.2 %</li></ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 5</summary>
        <p>Table 5 shows the distribution of AI applications that were the primary focus of the 66 reviews analyzed. It categorizes the reviews based on their main AI focus: General AIEd (covering various AI applications), Profiling and Prediction, Adaptive Systems and Personalisation, Assessment and Evaluation, and Intelligent Tutoring Systems. For each category, it provides the number (n) and percentage of reviews that fell under that focus.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "The reviews were categorised using Zawacki-Richter et al.’s (2019) classification (profiling and prediction; intelligent tutoring systems; adaptive systems and personalisation; assessment and evaluation; see Fig. 1), depending upon their purported focus within the title, abstract, keywords or search terms, with any reviews not specifying a particular focus categorised as ‘General AIEd’ (see Table 5)."</p>
            <p><strong>Context:</strong> This introduces Table 5 and explains how the reviews were categorized based on their focus, using the classification by Zawacki-Richter et al. (2019).</p>
        </div>
        
        <p><strong>Relevance:</strong> This table is important because it shows the main areas of focus within AIEd research in higher education. It helps to understand which AI applications are receiving the most attention in research and which areas might be under-researched.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is clear and easy to understand, with clear labels for each category.</li><li>The inclusion of both count and percentage for each category makes it easy to compare the relative focus on different AI applications.</li><li>The table could be visually enhanced by using color-coding or other visual cues to highlight the most prominent categories.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The table provides a good overview of the distribution of AI applications in the reviewed studies.</li><li>The high percentage of reviews focusing on General AIEd suggests that many studies explore a broad range of AI applications rather than focusing on a specific one.</li><li>The relatively low percentages for Assessment and Evaluation and Intelligent Tutoring Systems suggest these areas might be under-researched compared to others.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>General AIEd:</strong> 31 reviews</li><li><strong>Profiling and Prediction:</strong> 19 reviews</li><li><strong>Adaptive Systems and Personalisation:</strong> 18 reviews</li><li><strong>Assessment and Evaluation:</strong> 3 reviews</li><li><strong>Intelligent Tutoring Systems:</strong> 1 reviews</li></ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 6</summary>
        <p>Table 6 presents the top six reported benefits of using AI in higher education, based on the analysis of 31 reviews. It lists benefits like personalized learning, greater insight into student understanding, positive influence on learning outcomes, reduced planning and administration time for teachers, greater equity in education, and precise assessment &amp; feedback. For each benefit, the table shows the number of reviews that mentioned it and the corresponding percentage.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "Twelve benefits were identified across the 31 reviews (see Additional file 12: Appendix L), with personalised learning the most prominent (see Table 6)."</p>
            <p><strong>Context:</strong> This introduces Table 6, highlighting that it shows the top benefits of AI in higher education identified across the 31 general AIEd reviews.</p>
        </div>
        
        <p><strong>Relevance:</strong> This table is important because it summarizes the perceived advantages of using AI in higher education. It highlights the potential positive impacts of AI on various aspects of teaching, learning, and administration, which can inform decisions about AI adoption and implementation.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is clear and concise, presenting the benefits in a ranked order based on frequency.</li><li>The inclusion of both count and percentage for each benefit allows for easy comparison.</li><li>The table could be visually improved by using icons or other visual elements to represent each benefit.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The table effectively highlights the most frequently mentioned benefits of AI in higher education.</li><li>The prominence of personalized learning as a benefit aligns with the focus on adaptive systems and personalization in Table 5.</li><li>The table could be strengthened by providing more context or specific examples of how each benefit is realized in practice.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>Personalized learning:</strong> 12 reviews</li><li><strong>Greater insight into student understanding:</strong> 10 reviews</li><li><strong>Positive influence on learning outcomes:</strong> 10 reviews</li><li><strong>Reduced planning and administration time for teachers:</strong> 10 reviews</li><li><strong>Greater equity in education:</strong> 7 reviews</li><li><strong>Precise assessment &amp; feedback:</strong> 7 reviews</li></ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 7</summary>
        <p>Table 7 lists the top five challenges of implementing AI in higher education as identified across 31 reviews. These challenges include lack of ethical consideration, curriculum development needs, infrastructure limitations, lack of teacher technical knowledge, and shifting authority. The table provides the number and percentage of reviews that mentioned each challenge.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "The 31 reviews found 17 challenges, but these were mentioned in fewer studies than the benefits (see Additional file 12: Appendix L). Nine studies (see Table 7) reported a lack of ethical consideration, followed by curriculum development, infrastructure, lack of teacher technical knowledge, and shifting authority"</p>
            <p><strong>Context:</strong> This introduces Table 7 and explains that it presents the top five challenges identified in the 31 general AIEd reviews.</p>
        </div>
        
        <p><strong>Relevance:</strong> This table is important because it highlights the key obstacles to successful AI implementation in higher education. Understanding these challenges is crucial for developing strategies to overcome them and effectively integrate AI into educational settings.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is clear and easy to understand, with concise labels for each challenge.</li><li>The inclusion of both count and percentage for each challenge facilitates comparison.</li><li>The table could be visually enhanced by using color-coding or other visual cues to emphasize the most significant challenges.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The table effectively summarizes the most frequently mentioned challenges of AI implementation.</li><li>The prominence of ethical considerations as a challenge aligns with the research gaps identified in Table 8.</li><li>The table could be strengthened by providing more context or specific examples of how each challenge manifests in practice.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>Lack of ethical consideration:</strong> 9 reviews</li><li><strong>Curriculum development:</strong> 7 reviews</li><li><strong>Infrastructure:</strong> 7 reviews</li><li><strong>Lack of teacher technical knowledge:</strong> 7 reviews</li><li><strong>Shifting Authority:</strong> 7 reviews</li></ul></div>
    </details>
    
    <details class="non-text-element">
        <summary>table 8</summary>
        <p>Table 8 shows the top ten research gaps identified across the 66 studies included in the review. It lists each gap, the number of studies (n) that mentioned it, and the percentage (%) of the total studies that mentioned it. The gaps include ethical implications, the need for more diverse methodological approaches, more research within the field of Education, research with a wider range of stakeholders, interdisciplinary approaches, research beyond specific disciplines, research in a wider range of countries (especially developing countries), stronger theoretical foundations, longitudinal studies, and research beyond a few limited topics.</p>
        
        <div class="first-mention">
            <h5>First Mention</h5>
            <p><strong>Text:</strong> "Each review in this corpus (n = 66) was searched for any research gaps that had been identified within the primary studies, which were then coded inductively (see Additional file 1: Appendix A)."</p>
            <p><strong>Context:</strong> This explains that the research gaps were identified from the included studies and coded inductively. Appendix A is referenced for a full list.</p>
        </div>
        
        <p><strong>Relevance:</strong> This table is highly relevant as it summarizes the main areas where future research is needed in AIHEd, according to the synthesized reviews. It provides a clear direction for future research efforts and highlights the current limitations of the field.</p>
        
        <div class="critique-section">
            <div class="critique-title">Critique</div>
        
            <div class="critique-section">
                <div class="critique-title">Visual Aspects</div>
                <ul>
                <li>The table is clear and easy to understand, with clear headings and a simple structure.</li><li>The use of both raw counts (n) and percentages (%) helps to understand the prevalence of each gap.</li><li>The table could be visually improved by ordering the rows by percentage or count, to highlight the most prominent gaps.</li>
                </ul>
            </div>
            
            <div class="critique-section">
                <div class="critique-title">Analytical Aspects</div>
                <ul>
                <li>The identified gaps are relevant and important for the future development of AIHEd.</li><li>The gaps cover a range of issues, from ethical considerations to methodological limitations and the need for more diverse research contexts.</li><li>The table could be strengthened by providing more specific examples of research questions or topics within each gap area.</li>
                </ul>
            </div>
            </div>
        
        <div class="numeric-data">
            <h5>Numeric Data</h5>
            <ul>
        <li><strong>Ethical implications:</strong> 27 studies</li><li><strong>More methodological approaches needed:</strong> 24 studies</li><li><strong>More research in Education needed:</strong> 22 studies</li><li><strong>More research with a wider range of stakeholders:</strong> 14 studies</li><li><strong>Interdisciplinary approaches required:</strong> 11 studies</li><li><strong>Research limited to specific discipline areas:</strong> 11 studies</li><li><strong>More research in a wider range of countries, esp. developing:</strong> 10 studies</li><li><strong>Greater emphasis on theoretical foundations needed:</strong> 9 studies</li><li><strong>Longitudinal studies recommended:</strong> 8 studies</li><li><strong>Research limited to a few topics:</strong> 8 studies</li></ul></div>
    </details>
    
    
        </div>
        
        <div id="section-4" class="section">
            <h3>Discussion</h3>
            
            <h4>Overview</h4>
            <p>This discussion section summarizes the key findings of the meta-review on AI in higher education, highlighting the prevalence of adaptive systems and personalization, along with profiling and prediction. It emphasizes the need for increased ethics, collaboration, and rigor in future AIHEd research and practice. The discussion also addresses the global distribution of AIHEd research and the importance of open access publishing.</p>
            
            <h4>Key Aspects</h4>
            <ul><li><strong>Predominance of Adaptive Systems and Personalisation:</strong> The review found that most AIHEd research focuses on adaptive systems and personalization, followed by profiling and prediction.</li><li><strong>Benefits of AI in Higher Education:</strong> The discussion reiterates the benefits of AI, such as personalized learning, improved learning outcomes, and reduced administrative burden for teachers.</li><li><strong>Challenges of AI in Higher Education:</strong> The discussion highlights ethical concerns, curriculum development challenges, infrastructure limitations, and the need for increased teacher technical knowledge as key obstacles to AI adoption.</li><li><strong>Global Distribution of Research:</strong> The review found a diverse range of countries contributing to AIHEd research, but with less representation from certain regions.</li><li><strong>Call for Increased Ethics, Collaboration, and Rigor:</strong> The discussion emphasizes the need for greater attention to ethical considerations, increased collaboration among researchers and stakeholders, and improved methodological rigor in AIHEd research.</li></ul>
            
            <h4>Strengths</h4>
            <ul>
            
    <li>
        <strong>Clear Summary of Key Findings</strong>
        <p>The discussion effectively summarizes the main findings of the meta-review, providing a concise overview of the current state of AIHEd research.</p>
        <div class="quote">"By using the framework of Zawacki-Richter et al. (2019), this tertiary review of 66 AIHEd evidence syntheses found that most reviews report findings on the use of adaptive systems and personalisation tools, followed by profiling and prediction tools." (Page 32)</div>
    </li>
    
    <li>
        <strong>Addresses Both Benefits and Challenges</strong>
        <p>The discussion provides a balanced perspective by addressing both the benefits and challenges of AI in higher education, acknowledging the complexities of AI adoption.</p>
        <div class="quote">"This review of reviews confirms that the benefits of AI in higher education are multifold. ... However, the adoption of AI in higher education is not without challenges." (Page 32)</div>
    </li>
    
    <li>
        <strong>Highlights the Importance of Open Access</strong>
        <p>The discussion emphasizes the importance of open access publishing for disseminating research findings and reducing research waste, which is crucial for advancing the field.</p>
        <div class="quote">"only 67.7% of evidence synthesis in this sample were published open access ... This limits not only the ability of educators and researchers from lower resourced institutions to read these reviews, but it decreases its visibility generally, thereby increasing the likelihood that other researchers will duplicate effort" (Page 33)</div>
    </li>
    
            </ul>
            
            <h4>Suggestions for Improvement</h4>
            <ul>
            
    <li>
        <strong>Expand on the Implications for Different Disciplines</strong>
        <p>While the discussion mentions the maturity of AI applications in STEM and Health &amp; Welfare, further exploring the implications for other disciplines would be beneficial.</p>
        <div class="quote">"owing to the heavy predominance of primary AIHEd research in STEM and Health &amp; Welfare courses ... AI applications and presence within the curriculum appear to be at a more mature stage in those rather than in other disciplines." (Page 32)</div>
        <p><strong>Rationale:</strong> This would provide more tailored insights for educators and researchers in various fields.</p>
        <p><strong>Implementation:</strong> Discuss the specific opportunities and challenges of AI adoption in disciplines like humanities, social sciences, and arts, considering their unique pedagogical approaches and research practices.</p>
    </li>
    
    <li>
        <strong>Provide More Concrete Recommendations for Future Research</strong>
        <p>While the discussion identifies research gaps, providing more concrete recommendations for future research directions would be more actionable.</p>
        <div class="quote">"Future research will explore the full corpus of 307 AIEd evidence syntheses located across various educational levels, providing further insight into applications and future directions, alongside further guidance for the conduct of evidence synthesis." (Page 35)</div>
        <p><strong>Rationale:</strong> This would guide researchers in designing and conducting studies that address the identified gaps and advance the field.</p>
        <p><strong>Implementation:</strong> Formulate specific research questions or suggest research designs that could be used to investigate the ethical implications, collaborative approaches, and methodological rigor in AIHEd.</p>
    </li>
    
    <li>
        <strong>Discuss the Role of Policy and Institutional Support</strong>
        <p>The discussion focuses on research but could be strengthened by addressing the role of policy and institutional support in promoting ethical and effective AI adoption.</p>
        <div class="quote">"While AI offers promising avenues for enhancing educational experiences and outcomes, there are significant ethical, methodological, and pedagogical challenges that need to be addressed to harness its full potential effectively." (Page 35)</div>
        <p><strong>Rationale:</strong> This would broaden the discussion beyond research and acknowledge the importance of institutional factors in shaping AIEd practices.</p>
        <p><strong>Implementation:</strong> Discuss the need for policies and guidelines that address ethical considerations, data privacy, and responsible AI use in higher education. Suggest strategies for institutions to support faculty development in AI literacy and provide resources for implementing AIEd initiatives.</p>
    </li>
    
            </ul>
            
            
        </div>
        
        <div id="section-5" class="section">
            <h3>Conclusion</h3>
            
            <h4>Overview</h4>
            <p>This conclusion summarizes the meta-review&#39;s findings, emphasizing the dominance of adaptive systems and personalization in AIHEd research. It reiterates the need for increased ethics, collaboration, and rigor in the field, while also highlighting the global distribution of research and advocating for open access publishing.</p>
            
            <h4>Key Aspects</h4>
            <ul><li><strong>Dominant AI Applications:</strong> Adaptive systems and personalization, followed by profiling and prediction, are the most prevalent AI applications in higher education research.</li><li><strong>Benefits of AI:</strong> The conclusion reinforces the benefits of AI, such as personalized learning, improved learning outcomes, and reduced workload for educators.</li><li><strong>Challenges of AI:</strong> Ethical considerations, curriculum development, infrastructure limitations, and lack of teacher technical knowledge are highlighted as key challenges.</li><li><strong>Global Research Landscape:</strong> The conclusion acknowledges the global distribution of AIHEd research but notes underrepresentation from certain regions.</li><li><strong>Need for Ethics, Collaboration, and Rigor:</strong> The conclusion strongly advocates for increased attention to ethics, greater collaboration among researchers and stakeholders, and improved methodological rigor in AIHEd research.</li></ul>
            
            <h4>Strengths</h4>
            <ul>
            
    <li>
        <strong>Concise Summary of Findings</strong>
        <p>The conclusion effectively summarizes the main findings of the meta-review, providing a clear overview of the key themes and trends in AIHEd research.</p>
        <div class="quote">"This tertiary review synthesised the findings of 66 AIHEd evidence syntheses, with a view to map the field and gain an understanding of authorship patterns, research quality, key topics, common findings, and potential research gaps in the literature." (Page 34)</div>
    </li>
    
    <li>
        <strong>Balanced Perspective</strong>
        <p>The conclusion presents a balanced perspective by acknowledging both the promises and challenges of AI in higher education, avoiding overly optimistic or pessimistic views.</p>
        <div class="quote">"While AI offers promising avenues for enhancing educational experiences and outcomes, there are significant ethical, methodological, and pedagogical challenges that need to be addressed to harness its full potential effectively." (Page 35)</div>
    </li>
    
    <li>
        <strong>Clear Call to Action</strong>
        <p>The conclusion provides a clear call to action, urging researchers and practitioners to address the identified challenges and prioritize ethics, collaboration, and rigor in future AIHEd work.</p>
        <div class="quote">"there are significant ethical, methodological, and pedagogical challenges that need to be addressed to harness its full potential effectively." (Page 35)</div>
    </li>
    
            </ul>
            
            <h4>Suggestions for Improvement</h4>
            <ul>
            
    <li>
        <strong>Elaborate on Practical Implications</strong>
        <p>While the conclusion mentions the need for ethics, collaboration, and rigor, elaborating on the practical implications of these recommendations would be beneficial.</p>
        <div class="quote">"there are significant ethical, methodological, and pedagogical challenges that need to be addressed" (Page 35)</div>
        <p><strong>Rationale:</strong> This would provide more concrete guidance for researchers and practitioners on how to translate these principles into action.</p>
        <p><strong>Implementation:</strong> Provide specific examples of how to incorporate ethical considerations in AIEd research, foster collaboration among stakeholders, and improve methodological rigor in study design and reporting.</p>
    </li>
    
    <li>
        <strong>Discuss the Role of Educational Institutions</strong>
        <p>The conclusion focuses on researchers but could be strengthened by discussing the role of educational institutions in fostering responsible AI adoption.</p>
        <div class="quote">"While AI offers promising avenues for enhancing educational experiences and outcomes, there are significant ethical, methodological, and pedagogical challenges that need to be addressed to harness its full potential effectively." (Page 35)</div>
        <p><strong>Rationale:</strong> This would acknowledge the importance of institutional support in promoting ethical AI practices and creating a conducive environment for AIEd innovation.</p>
        <p><strong>Implementation:</strong> Discuss how institutions can develop policies and guidelines for AI use, provide training and resources for faculty and students, and establish ethical review boards for AIEd projects.</p>
    </li>
    
    <li>
        <strong>Connect to Broader Societal Implications</strong>
        <p>The conclusion could be broadened by connecting the findings and recommendations to the broader societal implications of AI in education.</p>
        <div class="quote">"While AI offers promising avenues for enhancing educational experiences and outcomes, there are significant ethical, methodological, and pedagogical challenges that need to be addressed to harness its full potential effectively." (Page 35)</div>
        <p><strong>Rationale:</strong> This would situate the discussion within a larger context and highlight the importance of responsible AI development and adoption for the future of education and society.</p>
        <p><strong>Implementation:</strong> Discuss the potential impact of AI on access to education, equity, and the changing nature of work and learning in the age of AI.</p>
    </li>
    
            </ul>
            
            
        </div>
        
    </div>
    
    <a href="#" class="back-to-top">↑ Back to Top</a>
    
    <script>
        // Show/hide back-to-top button
        window.onscroll = function() {
            var backToTopButton = document.querySelector('.back-to-top');
            if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
                backToTopButton.style.display = 'block';
            } else {
                backToTopButton.style.display = 'none';
            }
        };
    </script>
</body>
</html>
    